{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sani/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "mpl_style had been deprecated and will be removed in a future version.\n",
      "Use `matplotlib.pyplot.style.use` instead.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Konfigurasi Spark\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# 1. Lokasi di mana Spark diinstal\n",
    "spark_path = \"/Users/sani/Kuliah/Sem8/BigData/spark-2.1.0-bin-hadoop2.7\"\n",
    "\n",
    "# 2. Menentukan environment variable\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "\n",
    "\n",
    "# 3. Download winutils dari https://github.com/steveloughran/winutils/blob/master/hadoop-2.6.0/bin/winutils.exe?raw=true\n",
    "#   dan letakkan di dalam folder D:\\spark\\bin\\\n",
    "#   Lokasi winutils.exe\n",
    "os.environ['HADOOP_HOME'] = spark_path\n",
    "\n",
    "# 4. Lokasi Python yang dijalankan --> punya Anaconda\n",
    "#    Apabila Python yang diinstall hanya Anaconda, maka tidak perlu menjalankan baris ini.\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "# 5. Konfigurasi path library PySpark\n",
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.10.4-src.zip\")\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "# $example on$\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "# $example off$\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "# $example on$\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "# $example off$\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sc = SparkContext(appName=\"KMeansExample\")  # SparkContext\n",
    "\n",
    "# The usual preamble\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "pd.set_option('display.mpl_style', 'default')\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# This is necessary to show lots of columns in pandas 0.12. \n",
    "# Not necessary in pandas 0.13.\n",
    "pd.set_option('display.width', 5000) \n",
    "pd.set_option('display.max_columns', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sani/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3,4,5,6,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"file:///Users/sani/Kuliah/Sem8/BigData/Salaries.csv\", index_col = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeName             78\n",
       "JobTitle                  0\n",
       "BasePay                 605\n",
       "OvertimePay               0\n",
       "OtherPay                  0\n",
       "Benefits              36159\n",
       "TotalPay                  0\n",
       "TotalPayBenefits          0\n",
       "Year                      0\n",
       "Notes               1000029\n",
       "Agency               851375\n",
       "Status               961910\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Data Cleaning'''\n",
    "\n",
    "#check how many NaN values there are in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#delete unnecessary features\n",
    "\n",
    "#delete employee name, for sake of privacy \n",
    "del df['EmployeeName']\n",
    "\n",
    "#delete notes, 'Notes' column in empty \n",
    "del df['Notes']\n",
    "\n",
    "#delete 'Agency' column; all jobs are in SF\n",
    "del df['Agency']\n",
    "\n",
    "#delete any observation where JobTitle is 'Not provided'\n",
    "df = df[df.JobTitle != 'Not provided']\n",
    "\n",
    "#if 'Benefits' are NaN, fill with 0\n",
    "df['Benefits'].fillna(0, inplace=True)\n",
    "\n",
    "#Replace NaN status with \"Unknown\", since we don't know if its FT or PT work\n",
    "df['Status'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "#drop all rows with NaN values\n",
    "#all missing values are in \"BasePay\" column\n",
    "#We can afford to lose 605 observations of 148,654 obs. \n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobTitle            0\n",
      "BasePay             0\n",
      "OvertimePay         0\n",
      "OtherPay            0\n",
      "Benefits            0\n",
      "TotalPay            0\n",
      "TotalPayBenefits    0\n",
      "Year                0\n",
      "Status              0\n",
      "dtype: int64\n",
      "(                                          JobTitle BasePay OvertimePay OtherPay Benefits   TotalPay  TotalPayBenefits  Year   Status\n",
      "Id                                                                                                                                  \n",
      "1   GENERAL MANAGER-METROPOLITAN TRANSIT AUTHORITY  167411           0   400184        0  567595.43         567595.43  2011  Unknown\n",
      "2                  CAPTAIN III (POLICE DEPARTMENT)  155966      245132   137811        0  538909.28         538909.28  2011  Unknown\n",
      "3                  CAPTAIN III (POLICE DEPARTMENT)  212739      106088  16452.6        0  335279.91         335279.91  2011  Unknown\n",
      "4             WIRE ROPE CABLE MAINTENANCE MECHANIC   77916     56120.7   198307        0  332343.61         332343.61  2011  Unknown\n",
      "5     DEPUTY CHIEF OF DEPARTMENT,(FIRE DEPARTMENT)  134402        9737   182235        0  326373.19         326373.19  2011  Unknown, '\\n\\n')\n",
      "                             JobTitle  BasePay OvertimePay OtherPay Benefits  TotalPay  TotalPayBenefits  Year   Status\n",
      "Id                                                                                                                     \n",
      "1000025                Pool Lifeguard  4436.14           6    63.46    50.86   4493.60           4538.46  2016  Unknown\n",
      "1000026             Recreation Leader  4477.88           6    17.25    50.85   4489.13           4533.98  2016  Unknown\n",
      "1000027             Recreation Leader  4470.13           6    15.36    50.74   4479.49           4524.23  2016  Unknown\n",
      "1000028     Senior Telephone Operator  4335.64           6   148.26    50.72   4477.90           4522.62  2016  Unknown\n",
      "1000029  Public Svc Aide-Public Works  4476.97           6        6     50.7   4476.97           4521.67  2016  Unknown\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#no missing values\n",
    "print (df.isnull().sum())\n",
    "\n",
    "#preview data set\n",
    "print (df.head(), \"\\n\\n\")\n",
    "print (df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(167411.17999999999, 0.0, 400184.25),\n",
       " (155966.01999999999, 245131.88, 137811.38),\n",
       " (212739.13, 106088.17999999999, 16452.599999999999),\n",
       " (77916.0, 56120.709999999999, 198306.89999999999),\n",
       " (134401.60000000001, 9737.0, 182234.59),\n",
       " (118602.0, 8601.0, 189082.73999999999),\n",
       " (92492.009999999995, 89062.899999999994, 134426.14000000001),\n",
       " (256576.95999999999, 0.0, 51322.5),\n",
       " (176932.64000000001, 86362.679999999993, 40132.230000000003),\n",
       " (285262.0, 0.0, 17115.73),\n",
       " (194999.39000000001, 71344.880000000005, 33149.900000000001),\n",
       " (99722.0, 87082.619999999995, 110804.3),\n",
       " (294580.02000000002, 0.0, 0.0),\n",
       " (271329.03000000003, 0.0, 21342.59),\n",
       " (174872.64000000001, 74050.300000000003, 37424.110000000001),\n",
       " (198778.01000000001, 73478.199999999997, 13957.65),\n",
       " (268604.57000000001, 0.0, 16115.860000000001),\n",
       " (140546.87, 119397.25999999999, 18625.080000000002),\n",
       " (168692.63, 69626.119999999995, 38115.470000000001),\n",
       " (257510.59, 880.15999999999997, 16159.5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Base = pd.to_numeric(df['BasePay'], errors='coerce').dropna(how='any')\n",
    "Over = pd.to_numeric(df['OvertimePay'], errors='coerce').dropna(how='any')\n",
    "Other = pd.to_numeric(df['OtherPay'], errors='coerce').dropna(how='any')\n",
    "\n",
    "Pay=zip(Base,Over,Other)\n",
    "Pay[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pay=sc.parallelize(Pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Error = 14627401346.8\n"
     ]
    }
   ],
   "source": [
    "clusters = KMeans.train(pay,4, maxIterations=100, initializationMode=\"random\")\n",
    "    \n",
    "    # Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "WSSSE = pay.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdata=pay.map(lambda point: clusters.predict(point))\n",
    "clusterdata.take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pay.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = clusterdata.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for point in range(len(label)):\n",
    "    if (label[point]==0):\n",
    "        color = \"r\";\n",
    "    elif (label[point]==1):\n",
    "        color = \"y\"\n",
    "    elif (label[point]==2):\n",
    "        color = \"g\"\n",
    "    else:\n",
    "        color = \"b\";\n",
    "    lines = plt.plot(X[point][0], X[point][1], 'ro')\n",
    "    plt.setp(lines, color=color, linewidth=2.0)\n",
    "    center = clusters.clusterCenters\n",
    "print center\n",
    "for centroid in range(len(center)):\n",
    "    lines = plt.plot(center[centroid][0],center[centroid][1],'bx')\n",
    "    plt.setp(lines, color='w', markersize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
